import gradio as gr
import keyring
import base64
from openai import OpenAI

# Load the API key from the keyring
openai_api_key = keyring.get_password("VSCode", "openai_api_key")

# Initialize the OpenAI client
client = OpenAI( api_key=openai_api_key)

# Set the model to use
model_to_use = "gpt-4o"

# Open the image file and encode it as a base64 string
def encode_image(image_path):
    """
    Encode an image file as a base64 string.

    Parameters:
        image_path (str): The path to the image file.

    Returns:
        str: The base64 encoded string representation of the image.
    """
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode("utf-8")



def generate_chat_response(input, chat_history):
    """
    Generates a chat response using a remote GPT model.

    Args:
        input (dict): A dictionary containing the input text and optional files.
            input should be the object generated by the gradio chatbot interface.
            The input text is expected to be in the "text" key.
            The optional files are expected to be in the "files" key.
        chat_history (list): A list of previous chat messages. currently not in use, but coudl be used to make the model "remember" past messages

    Returns:
        str: The generated chat response.

    Raises:
        None

    Description:
        This function generates a chat response using a remote GPT model.
        It takes an input dictionary containing the input text and optional files (images).
        The input text is used as the user's message, and the optional files are added as images to the chat.
        The chat history is also added to the input messages.
        The generated chat response is returned as a string.
    """
    input_messages = []
    user_content = []
    input_messages.append({"role": "system", "content": "You are a helpful assistant that responds in Markdown."})
    user_content.append({"type": "text", "text": input["text"]})
    if input["files"] is not None:
        for file in input["files"]:
            base64_image = encode_image(file)
            user_content.append({"type": "image_url", "image_url": {
                "url": f"data:image/png;base64,{base64_image}"}})
            
    input_messages.append({"role": "user", "content": user_content})

    completion = client.chat.completions.create(
        model=model_to_use,
        messages=input_messages,
        temperature=0.5
    )
    content = completion.choices[0].message.content

    return content

def generate_gpt_summary(input_text, language="English"):
    """
    Generates a summary of the given input text using a remote GPT model.

    Args:
        input_text (str): The text to be summarized.
        language (str, optional): The language of the input text. Defaults to "English".

    Returns:
        str: The generated summary of the input text.
    """
    input_messages = []
    user_content = []
    input_messages.append({"role": "system", "content": f"You are a helpful assistant that help summarize text and responds in {language}."})
    user_content.append({"type": "text", "text": "summarize the following text: " + input_text})
            
    input_messages.append({"role": "user", "content": user_content})

    completion = client.chat.completions.create(
        model=model_to_use,
        messages=input_messages,
        temperature=0.5
    )
    content = completion.choices[0].message.content

    return content